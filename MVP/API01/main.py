%%writefile app.py
import streamlit as st
import os
import time
import base64
import json
import pandas as pd
# [ì¤‘ìš”] ë¬´ê±°ìš´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì—¬ê¸°ì„œ ë¡œë“œí•˜ì§€ ì•ŠìŒ (Lazy Loading)

# =========================================================
# 1. í˜ì´ì§€ ì„¤ì • & CSS (UI ë””ìì¸)
# =========================================================
st.set_page_config(page_title="Think:it Pro", page_icon="âš¡", layout="wide")

st.markdown("""
<style>
    /* ë©”ì¸ íƒ€ì´í‹€ */
    .main-title { font-size: 2.5rem; font-weight: bold; margin-bottom: 0.5rem; color: #222; }

    /* ì„¹ì…˜ í—¤ë” ìŠ¤íƒ€ì¼ */
    .section-header {
        font-size: 1.4rem; font-weight: bold; margin-top: 30px; margin-bottom: 15px;
        color: #333; border-left: 5px solid #FF4B4B; padding-left: 12px;
    }

    /* ì ìˆ˜ ì›í˜• UI */
    .score-circle-container { display: flex; justify-content: center; align-items: center; height: 100%; }
    .score-circle {
        position: relative; width: 160px; height: 160px; border-radius: 50%;
        border: 8px solid #FF4B4B; display: flex; justify-content: center;
        align-items: center; flex-direction: column; background-color: #fff;
        box-shadow: 0 4px 10px rgba(0,0,0,0.1);
    }
    .score-num { font-size: 4rem; font-weight: 900; color: #FF4B4B; line-height: 1; }
    .score-max { font-size: 1.2rem; color: #999; font-weight: normal; }
    .score-comment { text-align: center; font-size: 1.2rem; font-weight: bold; color: #555; margin-top: 15px; }

    /* íŒŒì¼ ì •ë³´ ì¹´ë“œ */
    .info-card {
        background-color: #f8f9fa; border: 1px solid #ddd; border-radius: 12px;
        padding: 20px; height: 100%; display: flex; flex-direction: column; justify-content: center;
    }
    .info-label { font-size: 0.9rem; color: #666; font-weight: bold; }
    .info-value { font-size: 1.2rem; color: #333; font-weight: bold; margin-bottom: 10px; }

    /* ìš”ì•½ ì¹´ë“œ */
    .summary-card {
        background-color: #fff; border: 2px solid #eee; border-radius: 12px;
        padding: 20px; box-shadow: 0 2px 8px rgba(0,0,0,0.05); margin-bottom: 20px;
    }

    /* ë­í‚¹ ë°°ì§€ */
    .rank-tag {
        display: block; width: 100%; text-align: center;
        padding: 8px 0; border-radius: 8px; font-weight: bold; color: white; margin-bottom: 10px;
    }
    .bg-1 { background-color: #FFD700; color: #333; }
    .bg-2 { background-color: #C0C0C0; color: #333; }
    .bg-3 { background-color: #CD7F32; color: white; }

    /* ì—…ë¡œë” */
    .stFileUploader { padding: 15px; border: 2px dashed #FF4B4B; border-radius: 15px; text-align: center;}
</style>
""", unsafe_allow_html=True)

# =========================================================
# 2. UI ê·¸ë¦¬ê¸° (ì´ˆê¸° í™”ë©´)
# =========================================================
st.markdown('<div class="main-title">âœ¨ Think:it Pro | AI ì»¨ì„¤íŒ…</div>', unsafe_allow_html=True)

# ë°ì´í„° ë¡œë“œ
@st.cache_data
def load_benchmark_data():
    if os.path.exists("youtube_top200_data.csv"):
        return pd.read_csv("youtube_top200_data.csv")
    return pd.DataFrame()

df = load_benchmark_data()
cat_list = df['Category_Name'].unique() if not df.empty else ["General", "Vlog", "Gaming"]

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ“Š ì„¤ì •")
    category = st.selectbox("ì¹´í…Œê³ ë¦¬ ì„ íƒ", cat_list)
    st.info("ğŸ’¡ Cloudflare Tunnelë¡œ ì—°ê²°ë˜ì–´ í›¨ì”¬ ë¹ ë¦…ë‹ˆë‹¤.")

# ë©”ì¸ ì—…ë¡œë”
with st.expander("ğŸ“¤ ì˜ìƒ íŒŒì¼ ì—…ë¡œë“œ (MP4)", expanded=True):
    uploaded_file = st.file_uploader("ì—¬ê¸°ì— íŒŒì¼ì„ ë“œë˜ê·¸í•˜ê±°ë‚˜ ì„ íƒí•˜ì„¸ìš”", type=["mp4"])

# =========================================================
# 3. ë¶„ì„ ë¡œì§ (ë²„íŠ¼ í´ë¦­ ì‹œ ì‹¤í–‰)
# =========================================================
if uploaded_file:
    tfile = "temp_input.mp4"
    with open(tfile, "wb") as f:
        f.write(uploaded_file.read())
    
    if st.button("ğŸš€ AI ë°ì´í„° ë¶„ì„ ì‹œì‘ (Click)", type="primary", use_container_width=True):
        
        with st.status("âš™ï¸ AI ì—”ì§„ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì¤‘...", expanded=True) as status:
            # ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”©
            try:
                import torch
                import cv2
                from moviepy.editor import VideoFileClip
                from openai import OpenAI
                from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline
                from google.colab import userdata
                import numpy as np
                import re
                from collections import Counter
            except ImportError as e:
                st.error(f"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ì‹¤íŒ¨: {e}")
                st.stop()

            # API í‚¤ í™•ì¸
            try:
                api_key = userdata.get('OPENAI_API_KEY')
                client = OpenAI(api_key=api_key)
            except:
                try:
                    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
                except:
                    st.error("ğŸš¨ API í‚¤ ì˜¤ë¥˜! ë³´ì•ˆ ë¹„ë°€ì„ í™•ì¸í•˜ì„¸ìš”.")
                    st.stop()

            # ëª¨ë¸ ë¡œë“œ
            @st.cache_resource
            def load_models():
                device = "cuda:0" if torch.cuda.is_available() else "cpu"
                torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32
                model_id = "openai/whisper-large-v3"
                model = AutoModelForSpeechSeq2Seq.from_pretrained(
                    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True
                )
                model.to(device)
                processor = AutoProcessor.from_pretrained(model_id)
                pipe = pipeline(
                    "automatic-speech-recognition", model=model, tokenizer=processor.tokenizer,
                    feature_extractor=processor.feature_extractor, max_new_tokens=128,
                    chunk_length_s=30, batch_size=16, return_timestamps=True,
                    torch_dtype=torch_dtype, device=device,
                )
                return pipe

            st.write("ğŸ™ï¸ Whisper ëª¨ë¸ ì¤€ë¹„ ì¤‘...")
            whisper_pipe = load_models()
            
            # ë°ì´í„° ì¶”ì¶œ
            st.write("ğŸ‘€ ì˜ìƒ ë° ì˜¤ë””ì˜¤ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
            clip = VideoFileClip(tfile)
            audio_path = "temp_audio.mp3"
            clip.audio.write_audiofile(audio_path, logger=None)
            transcription = whisper_pipe(audio_path, generate_kwargs={"language": "korean"})
            text = transcription["text"]
            duration = clip.duration
            wpm = (len(text.split()) / duration) * 60
            
            # Vision
            cap = cv2.VideoCapture(tfile)
            frames_data = []
            timestamps = [duration * 0.15, duration * 0.5, duration * 0.85]
            
            def encode_image(img):
                _, buffer = cv2.imencode('.jpg', img)
                return base64.b64encode(buffer).decode('utf-8')

            for t in timestamps:
                cap.set(cv2.CAP_PROP_POS_MSEC, t * 1000)
                ret, frame = cap.read()
                if ret:
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                    frames_data.append({
                        "img": frame_rgb, "time_str": time.strftime('%M:%S', time.gmtime(t)),
                        "time_sec": t,
                        "b64": encode_image(frame_bgr)
                    })
            cap.release()
            clip.close()
            if os.path.exists(audio_path): os.remove(audio_path)

            # GPT-4o ë¶„ì„
            st.write("ğŸ§  GPT-4o ì‹¬ì¸µ ë¶„ì„ ì¤‘...")
            prompt = f"""
            ë‹¹ì‹ ì€ ë°ì´í„° ê¸°ë°˜ì˜ ëƒ‰ì² í•œ 'ìœ íŠœë¸Œ ì „ë¬¸ ì»¨ì„¤í„´íŠ¸'ì…ë‹ˆë‹¤.
            í˜„ì¬ ë¶„ì„í•  ì˜ìƒì˜ ì¹´í…Œê³ ë¦¬ëŠ” '{category}'ì…ë‹ˆë‹¤.
            [ì‚¬ìš©ì ì˜ìƒ ë°ì´í„°]
            - ëŒ€ë³¸(Script): {text[:1500]}... (ì¼ë¶€ ë°œì·Œ)
            - ë°œí™” ì†ë„(WPM): {int(wpm)}
            
            ì œê³µëœ ì‹œê° ë°ì´í„°(ì¸ë„¤ì¼ í›„ë³´ í”„ë ˆì„)ì™€ ëŒ€ë³¸ì„ ì¢…í•©í•˜ì—¬ ë¶„ì„í•˜ì„¸ìš”.
            ë°˜ë“œì‹œ ì•„ë˜ JSON í¬ë§·ì„ ì¤€ìˆ˜í•˜ì—¬ 'í•œêµ­ì–´'ë¡œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
            {{
                "score": (0~100 ì‚¬ì´ì˜ ì •ìˆ˜ ì ìˆ˜),
                "score_comment": (ì ìˆ˜ì— ëŒ€í•œ í•œ ì¤„ ì½”ë©˜íŠ¸),
                "summary_points": ["í•µì‹¬ ì „ëµ 1", "í•µì‹¬ ì „ëµ 2"],
                "scene_reasons": ["1ìˆœìœ„ ì´ìœ ", "2ìˆœìœ„ ì´ìœ ", "3ìˆœìœ„ ì´ìœ "],
                "titles": [
                    {{"text": "ì œëª© 1", "why": "ì´ìœ "}},
                    {{"text": "ì œëª© 2", "why": "ì´ìœ "}},
                    {{"text": "ì œëª© 3", "why": "ì´ìœ "}}
                ],
                "detail_analysis": (ìƒì„¸ ë¶„ì„ í”¼ë“œë°±)
            }}
            """
            
            content = [{"type": "text", "text": prompt}]
            for fd in frames_data:
                content.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{fd['b64']}"}})
            
            response = client.chat.completions.create(
                model="gpt-4o", messages=[{"role": "user", "content": content}], response_format={"type": "json_object"}
            )
            result = json.loads(response.choices[0].message.content)
            status.update(label="âœ… ë¶„ì„ ì™„ë£Œ!", state="complete", expanded=False)

        # =========================================================
        # 4. ê²°ê³¼ UI êµ¬í˜„ (ìš”ì²­í•˜ì‹  ìˆœì„œëŒ€ë¡œ ë°°ì¹˜)
        # =========================================================
        st.divider()

        # ---------------------------------------------------------
        # [1] ìƒë‹¨: (ì™¼ìª½) ì¢…í•© ì ìˆ˜ / (ì˜¤ë¥¸ìª½) íŒŒì¼ ì •ë³´
        # ---------------------------------------------------------
        col_top_L, col_top_R = st.columns([1, 1], gap="medium")

        with col_top_L:
            st.markdown('<div class="section-header" style="text-align:center;">ğŸ† ì¢…í•© íŠ¸ë Œë“œ ì í•©ë„</div>', unsafe_allow_html=True)
            st.markdown(f"""
            <div class="score-circle-container">
                <div class="score-circle">
                    <div class="score-num">{result['score']}</div>
                    <div class="score-max">/ 100</div>
                </div>
            </div>
            <div class="score-comment">{result['score_comment']}</div>
            """, unsafe_allow_html=True)

        with col_top_R:
            st.markdown('<div class="section-header">ğŸ“ íŒŒì¼ ì •ë³´</div>', unsafe_allow_html=True)
            st.markdown(f"""
            <div class="info-card">
                <div><span class="info-label">íŒŒì¼ëª…</span><div class="info-value">{uploaded_file.name}</div></div>
                <div style="margin-top:15px;"><span class="info-label">ì¹´í…Œê³ ë¦¬</span><div class="info-value">{category}</div></div>
                <div style="margin-top:15px;"><span class="info-label">ë°œí™” ì†ë„</span><div class="info-value">{int(wpm)} WPM</div></div>
            </div>
            """, unsafe_allow_html=True)

        st.markdown("---")

        # ---------------------------------------------------------
        # [2] ì¤‘ë‹¨: 1, 2, 3ìˆœìœ„ ì¥ë©´ (ê°™ì€ ì‚¬ì´ì¦ˆë¡œ ê°€ë¡œ ë°°ì¹˜)
        # ---------------------------------------------------------
        st.markdown('<div class="section-header">ğŸ“¸ ì¸ë„¤ì¼ ì¥ë©´ ì¶”ì²œ (Best 3)</div>', unsafe_allow_html=True)
        
        # 3ê°œì˜ ë™ì¼í•œ í¬ê¸° ì»¬ëŸ¼ ìƒì„±
        thumb_c1, thumb_c2, thumb_c3 = st.columns(3, gap="medium")

        with thumb_c1:
            st.markdown(f'<span class="rank-tag bg-1">ğŸ¥‡ 1ìˆœìœ„ ({frames_data[0]["time_str"]})</span>', unsafe_allow_html=True)
            st.video(tfile, start_time=int(frames_data[0]['time_sec']))
            st.caption(f"ğŸ’¡ {result['scene_reasons'][0]}")

        with thumb_c2:
            st.markdown(f'<span class="rank-tag bg-2">ğŸ¥ˆ 2ìˆœìœ„ ({frames_data[1]["time_str"]})</span>', unsafe_allow_html=True)
            st.video(tfile, start_time=int(frames_data[1]['time_sec']))
            st.caption(f"ğŸ’¡ {result['scene_reasons'][1]}")

        with thumb_c3:
            st.markdown(f'<span class="rank-tag bg-3">ğŸ¥‰ 3ìˆœìœ„ ({frames_data[2]["time_str"]})</span>', unsafe_allow_html=True)
            st.video(tfile, start_time=int(frames_data[2]['time_sec']))
            st.caption(f"ğŸ’¡ {result['scene_reasons'][2]}")

        st.markdown("---")

        # ---------------------------------------------------------
        # [3] í•˜ë‹¨: ë‚˜ë¨¸ì§€ ì •ë³´ ìˆœì°¨ì  ë””ìŠ¤í”Œë ˆì´ (í•œ ì¤„ì”©)
        # ---------------------------------------------------------
        
        # (3-1) í•µì‹¬ ì „ëµ ìš”ì•½
        st.markdown('<div class="section-header">ğŸ“ í•µì‹¬ ì „ëµ ìš”ì•½</div>', unsafe_allow_html=True)
        st.markdown(f"""
        <div class="summary-card">
            <ul style="font-size: 1.1rem; line-height: 1.8;">
                <li><b>ì „ëµ 1:</b> {result['summary_points'][0]}</li>
                <li><b>ì „ëµ 2:</b> {result['summary_points'][1]}</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

        # (3-2) ì œëª© ì¶”ì²œ
        st.markdown('<div class="section-header" style="margin-top: 40px;">ğŸ·ï¸ í´ë¦­ì„ ë¶€ë¥´ëŠ” ì œëª© ì¶”ì²œ</div>', unsafe_allow_html=True)
        for i, t in enumerate(result['titles']):
            with st.expander(f"ğŸ“ ì¶”ì²œ {i+1}: {t['text']}", expanded=True):
                st.info(f"**WHY?** {t['why']}")

        # (3-3) ìƒì„¸ ë¶„ì„
        st.markdown('<div class="section-header" style="margin-top: 40px;">ğŸ“Š AI ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸</div>', unsafe_allow_html=True)
        with st.container():
            st.markdown(f"""
            <div style="background-color:#fff; padding:20px; border-radius:10px; border:1px solid #ddd; line-height:1.6;">
                {result['detail_analysis']}
            </div>
            """, unsafe_allow_html=True)
