import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import os

# 1. í•œê¸€ í°íŠ¸ ì„¤ì¹˜ (ë‚˜ëˆ”ë°”ë¥¸ê³ ë”•)
# -qq : ë¡œê·¸ ìµœì†Œí™”
!sudo apt-get -qq install -y fonts-nanum

# 2. í°íŠ¸ ìºì‹œ ì—…ë°ì´íŠ¸ (í˜¹ì‹œ ëª¨ë¥¼ ì˜¤ë¥˜ ë°©ì§€)
!rm -rf ~/.cache/matplotlib

# 3. Matplotlibì— í°íŠ¸ ì¶”ê°€ (ëŸ°íƒ€ì„ ì¬ì‹œì‘ ì—†ì´ ì ìš©í•˜ê¸° ìœ„í•¨)
font_path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'

if os.path.exists(font_path):
    fm.fontManager.addfont(font_path)
    plt.rc('font', family='NanumBarunGothic')

    # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€
    plt.rcParams['axes.unicode_minus'] = False
    print("âœ… í•œê¸€ í°íŠ¸(ë‚˜ëˆ”ë°”ë¥¸ê³ ë”•)ê°€ ì„±ê³µì ìœ¼ë¡œ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    print("âŒ í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜ê°€ ì œëŒ€ë¡œ ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    # @title ğŸš€ 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

import os
import matplotlib as mpl
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# 1. í•œê¸€ í°íŠ¸ ì„¤ì¹˜ (ë‚˜ëˆ”ë°”ë¥¸ê³ ë”•)
print("â³ í•œê¸€ í°íŠ¸ ë° í˜•íƒœì†Œ ë¶„ì„ê¸° ì„¤ì¹˜ ì¤‘... (ì•½ 1~2ë¶„ ì†Œìš”)")
!sudo apt-get install -y fonts-nanum -q
!sudo fc-cache -fv
!rm ~/.cache/matplotlib -rf
!pip install konlpy -q

# 2. í°íŠ¸ ì„¤ì •
plt.rc('font', family='NanumBarunGothic')
mpl.rcParams['axes.unicode_minus'] = False # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

print("âœ… ì„¤ì¹˜ ì™„ë£Œ! ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")

# @title ğŸ“Š 2. íŠ¸ë Œë“œ ë¶„ì„ ë¡œì§ ì‹¤í–‰ (ë°ì´í„° ë¶„ì„ & ì‹œê°í™”)

from konlpy.tag import Okt
from collections import Counter
import re
import pandas as pd

# ==========================================
# 1. ë”ë¯¸ ë°ì´í„° ìƒì„± (YouTube API ëŒ€ìš©)
# ==========================================
raw_data = {
    "ì—¬í–‰": [
        "ë¯¿ì„ ìˆ˜ ì—†ëŠ” ë‚˜ì˜ ì‹ í˜¼ì—¬í–‰ ë¸Œì´ë¡œê·¸",
        "ì¤‘êµ­ ë² ì´ì§•ì—ì„œ 10,000ì›ìœ¼ë¡œ í•  ìˆ˜ ìˆëŠ” ê²ƒë“¤",
        "ë‚˜í˜¼ì ê°•ë¦‰ ë‹¹ì¼ì¹˜ê¸°",
        "ìˆœìˆ˜í•œ ëŒ€ìì—°ê³¼ ë”°ëœ»í•œ ì‚¬ëŒë“¤ì˜ ë•…, ë‘ ë‹¬ê°„ì˜ ì¤‘ì•™ì•„ì‹œì•„ ìì „ê±° ì—¬í–‰ (í’€ë²„ì „)",
        "ë¶€ëª¨ë‹˜ ëª¨ì‹œê³  ê°€ê¸° ì¢‹ì€ ë² íŠ¸ë‚¨ ì—¬í–‰",
        "í•œêµ­ì¸ ë§Œì¡±ë„ 1ìœ„ ì—¬í–‰ì§€, ì •ë§ ê·¸ë ‡ê²Œ ì¢‹ì„ê¹Œ? ì†”ì§í•˜ê²Œ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.",
        "ë¬¼ê°€ ì €ë ´í•œ ìœ ëŸ½ì—ì„œ ëˆ„êµ¬ë‚˜ ê¿ˆê¾¸ëŠ” í•œë‹¬ì‚´ì´ ë¡œë§",
        "ì•Œì°¬ ë‰´ìš•ì—ì„œì˜ ì¼ì£¼ì¼ ëœë¤ì—¬í–‰ ì„¸í¬ë¼ í•˜ìš¸ ë³´ìŠ¤í„´ ë‹¹ì¼ì¹˜ê¸°",
        "í›„ì¿ ì˜¤ì¹´ ì˜¨ì²œ ì—¬í–‰ 2ë°• 3ì¼ ì½”ìŠ¤ ì¶”ì²œ",
        "ì˜¤ì‚¬ì¹´ ìœ ë‹ˆë²„ì…œ ë‹Œí…ë„ ì›”ë“œ ì…ì¥ê¶Œ ì‹¸ê²Œ ì‚¬ëŠ” ë²•",
        "ì—”ì € í˜„ìƒ, ì§€ê¸ˆ ì¼ë³¸ ì—¬í–‰ ê°€ì•¼í•˜ëŠ” ì´ìœ ",
        "ì‚¿í¬ë¡œ ëˆˆì¶•ì œ ì‹¤ì‹œê°„ í˜„í™©, ë¹„í–‰ê¸°í‘œ ê°€ê²©",
        "ë‹¤ë‚­ ë¦¬ì¡°íŠ¸ ì¶”ì²œ, ê°€ì¡± ì—¬í–‰ ìˆ™ì†Œ ë¹„êµ"
    ],
    "IT/í…Œí¬": [
        "ê°¤ëŸ­ì‹œ S24 ìš¸íŠ¸ë¼ ì–¸ë°•ì‹±, ì•„ì´í°15 ë¹„êµ",
        "ê°€ì„±ë¹„ ë…¸íŠ¸ë¶ ì¶”ì²œ Top 5, ëŒ€í•™ìƒ ë…¸íŠ¸ë¶",
        "ì•„ì´í°15 í”„ë¡œ ë°œì—´ í…ŒìŠ¤íŠ¸, ë°°í„°ë¦¬ ì„±ëŠ¥",
        "ë§¥ë¶ ì—ì–´ M3 ì¶œì‹œì¼ ë£¨ë¨¸ ì´ì •ë¦¬",
        "ê°¤ëŸ­ì‹œ S24 AI ê¸°ëŠ¥ ì‹¤ì‚¬ìš©ê¸°, í†µì—­ ê¸°ëŠ¥ ëŒ€ë°•",
        "ì•Œë¦¬ìµìŠ¤í”„ë ˆìŠ¤ ê°€ì„±ë¹„ ê¸°ê³„ì‹ í‚¤ë³´ë“œ ì¶”ì²œ",
        "ì• í”Œ ë¹„ì „ í”„ë¡œ ì°©ìš© í›„ê¸°, ê³µê°„ ì»´í“¨í„°ì˜ ë¯¸ë˜",
        "ì‚¼ì„± ê°¤ëŸ­ì‹œ ë§ ë””ìì¸ ìœ ì¶œ, ì¶œì‹œì¼ ì˜ˆìƒ"
    ],
    "ìš”ë¦¬/ìì·¨": [
        "ìì·¨ìƒ í•„ìˆ˜, 1ë¶„ ì™„ì„± ê³„ë€ ë³¶ìŒë°¥ ë ˆì‹œí”¼",
        "í¸ì˜ì  ê¿€ì¡°í•© ë ˆì‹œí”¼, ë¶ˆë‹­ë³¶ìŒë©´ ë§›ìˆê²Œ ë¨¹ëŠ” ë²•",
        "ì¼ì£¼ì¼ ë°˜ì°¬ ë§Œë“¤ê¸°, ì½©ë‚˜ë¬¼ ë¬´ì¹¨ í™©ê¸ˆë ˆì‹œí”¼",
        "ë‹¤ì´ì–´íŠ¸ ìš”ë¦¬, ë‹­ê°€ìŠ´ì‚´ ìƒëŸ¬ë“œ ë“œë ˆì‹± ë§Œë“¤ê¸°",
        "ë°±ì¢…ì› ê¹€ì¹˜ì°Œê°œ ë§›ìˆê²Œ ë“ì´ëŠ” ë²•, ë¹„ë°€ ì¬ë£Œ",
        "ì—ì–´í”„ë¼ì´ì–´ ì‚¼ê²¹ì‚´ êµ½ê¸°, ê²‰ë°”ì†ì´‰ ë¹„ë²•",
        "ì´ˆê°„ë‹¨ ì „ìë ˆì¸ì§€ ìš”ë¦¬ ëª¨ìŒ BEST 5"
    ]
}

# ==========================================
# 2. ë¶„ì„ ì—”ì§„ (NLP ë¡œì§)
# ==========================================

def analyze_trend(category_name, titles):
    okt = Okt()

    # ë¶ˆìš©ì–´(Stopwords): ë¶„ì„ì—ì„œ ì œì™¸í•  ì¼ë°˜ì ì¸ ë‹¨ì–´ë“¤
    stopwords = [
        # 'ì—¬í–‰', 'ë¸Œì´ë¡œê·¸', 'ì¶”ì²œ', 'ì´ì •ë¦¬', 'í›„ê¸°', 'ì½”ìŠ¤', 'ì˜ìƒ', 'ì˜¤ëŠ˜', 'ê³µê°œ',
        # 'ë¹„êµ', 'ëŒ€ë°•', 'ì´ìœ ', 'ì–¸ë°•ì‹±', 'í…ŒìŠ¤íŠ¸', 'ê¸°ëŠ¥', 'ì‚¬ìš©', 'ë§Œë“¤ê¸°', 'ë°©ë²•', 'ë ˆì‹œí”¼'
        'ë¸Œì´', 'ë¡œê·¸'
    ]

    # ì¹´í…Œê³ ë¦¬ ì´ë¦„ ìì²´ë„ ë¶ˆìš©ì–´ ì²˜ë¦¬ (ì˜ˆ: ì—¬í–‰ ì¹´í…Œê³ ë¦¬ì—ì„œ 'ì—¬í–‰' ì œê±°)
    stopwords.append(category_name.split('/')[0])

    noun_list = []

    for title in titles:
        # 1. ì „ì²˜ë¦¬: íŠ¹ìˆ˜ë¬¸ì ì œê±°
        clean_title = re.sub(r'[^\w\s]', '', title)

        # 2. ëª…ì‚¬ ì¶”ì¶œ
        nouns = okt.nouns(clean_title)

        # 3. í•„í„°ë§ (ë¶ˆìš©ì–´ ì œì™¸, 2ê¸€ì ì´ìƒ)
        filtered_nouns = [n for n in nouns if n not in stopwords and len(n) > 1]

        # 4. ë³µí•© ëª…ì‚¬ (Bi-gram) ì¶”ì¶œ ë¡œì§ (ì˜ˆ: ê°¤ëŸ­ì‹œ + S24 -> ê°¤ëŸ­ì‹œ S24)
        # ì•ë’¤ ë‹¨ì–´ê°€ ë§¥ë½ìƒ ì´ì–´ì§€ëŠ” ê²½ìš°ë¥¼ ì°¾ê¸° ìœ„í•´ ì›ë³¸ íƒ€ì´í‹€ ê¸°ë°˜ìœ¼ë¡œ ì²´í¬í•˜ê±°ë‚˜
        # ê°„ë‹¨í•˜ê²Œ ì—°ì†ëœ ëª…ì‚¬ë¥¼ ë¬¶ì–´ì„œ íŠ¸ë Œë“œ í‚¤ì›Œë“œë¡œ ì¡ìŒ
        for i in range(len(filtered_nouns) - 1):
            bigram = f"{filtered_nouns[i]} {filtered_nouns[i+1]}"
            noun_list.append(bigram) # ë³µí•© ëª…ì‚¬ ì¶”ê°€

        noun_list.extend(filtered_nouns) # ë‹¨ì¼ ëª…ì‚¬ë„ ì¶”ê°€

    # ë¹ˆë„ìˆ˜ ê³„ì‚°
    count = Counter(noun_list)
    return count.most_common(7) # ìƒìœ„ 7ê°œë§Œ ë¦¬í„´

# ==========================================
# 3. ì‹œê°í™” (Matplotlib)
# ==========================================

def plot_trends(data):
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    colors = ['#FF6B6B', '#4ECDC4', '#FFD93D'] # íŒŒìŠ¤í…”í†¤ ì»¬ëŸ¬

    for i, (category, titles) in enumerate(data.items()):
        # ë¶„ì„ ì‹¤í–‰
        top_keywords = analyze_trend(category, titles)

        # ë°ì´í„° ë¶„ë¦¬
        words = [k[0] for k in top_keywords]
        counts = [k[1] for k in top_keywords]

        # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
        ax = axes[i]
        bars = ax.barh(words, counts, color=colors[i], alpha=0.8)
        ax.invert_yaxis() # ìƒìœ„ í‚¤ì›Œë“œê°€ ìœ„ë¡œ ì˜¤ê²Œ
        ax.set_title(f"Target: {category}", fontsize=15, fontweight='bold')
        ax.set_xlabel("ì–¸ê¸‰ ë¹ˆë„(Trend Score)")

        # ë°” ì˜†ì— ìˆ˜ì¹˜ í‘œì‹œ
        for bar in bars:
            width = bar.get_width()
            ax.text(width + 0.1, bar.get_y() + bar.get_height()/2,
                    f'{int(width)}', ha='left', va='center', fontsize=10)

    plt.suptitle("ğŸ¥ YouTube ì¹´í…Œê³ ë¦¬ë³„ íŠ¸ë Œë”© í† í”½ ë¶„ì„ ê²°ê³¼", fontsize=20, fontweight='bold')
    plt.tight_layout()
    plt.show()

# ì‹¤í–‰
print("ğŸ¤– AIê°€ ì œëª©ì„ ë¶„ì„í•˜ì—¬ íŠ¸ë Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤...")
plot_trends(raw_data)

# @title ğŸ’¸í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
!pip install -q openai pandas

import os
import json
import pandas as pd
from openai import OpenAI
from IPython.display import display, Markdown

# ==========================================
# [Backend Simulation] íŠ¸ë Œë“œ DB
# ==========================================
TREND_DB = {
    "ì—¬í–‰": ["ì˜¤ì‚¬ì¹´", "ì—”ì €", "ê°€ì„±ë¹„", "í¸ì˜ì ", "2ë°•3ì¼"],
    "ìš”ë¦¬": ["1ë¶„ ë ˆì‹œí”¼", "ìì·¨ ìš”ë¦¬", "ë¶ˆë‹­ë³¶ìŒë©´", "ë‹¤ì´ì–´íŠ¸"],
    "IT/í…Œí¬": ["ê°¤ëŸ­ì‹œS24", "ì•„ì´í°15", "ê°€ì„±ë¹„ ë…¸íŠ¸ë¶", "AI ê¸°ëŠ¥"],
}

print("âœ… ì„¤ì • ì™„ë£Œ")

# @title ğŸ› ï¸ í‚¤ì›Œë“œ ê¸°ë°˜ ë§ì¶¤í˜• ì œëª© ì¶”ì²œ ì‹œì—°

import os
import json
import pandas as pd
from openai import OpenAI
from IPython.display import display

# ==========================================
# 1. í™˜ê²½ ì„¤ì • ë° ë°ì´í„° (ê°€ì¥ ë¨¼ì € ì‹¤í–‰)
# ==========================================
TREND_DB = {
    "ì—¬í–‰": ["ì˜¤ì‚¬ì¹´", "ì—”ì €", "ê°€ì„±ë¹„", "í¸ì˜ì ", "2ë°•3ì¼"],
    "ìš”ë¦¬": ["1ë¶„ ë ˆì‹œí”¼", "ìì·¨ ìš”ë¦¬", "ë¶ˆë‹­ë³¶ìŒë©´", "ë‹¤ì´ì–´íŠ¸"],
    "IT/í…Œí¬": ["ê°¤ëŸ­ì‹œS24", "ì•„ì´í°15", "ê°€ì„±ë¹„ ë…¸íŠ¸ë¶", "AI ê¸°ëŠ¥"],
}

# ==========================================
# 2. ë”ë¯¸ ë°ì´í„° í•¨ìˆ˜
# ==========================================
def mock_response_data(keywords):
    return {
        "suggestions": [
            {
                "title": f"[Mock] {keywords[0]} ì—¬í–‰ ì¢…ê²°! 10ë§Œì›ìœ¼ë¡œ ëë‚´ê¸°",
                "strategy": "ê°€ì„±ë¹„ (ì‹œë®¬ë ˆì´ì…˜)",
                "keywords_used": [keywords[0]]
            },
            {
                "title": f"[Mock] ì ˆëŒ€ ì‹¤íŒ¨ ì—†ëŠ” {keywords[1]} ì¶”ì²œ",
                "strategy": "ê¶Œìœ„ (ì‹œë®¬ë ˆì´ì…˜)",
                "keywords_used": [keywords[1]]
            }
        ]
    }

# ==========================================
# 3. ë©”ì¸ AI ì—”ì§„ (GPT-4o-mini)
# ==========================================
def generate_titles_final(api_key, category, video_summary, target_audience):

    # íŠ¸ë Œë“œ í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
    keywords = TREND_DB.get(category, ["í™”ì œ", "ì´ìŠˆ"])
    keywords_str = ", ".join(keywords)

    # API í‚¤ê°€ ì—†ìœ¼ë©´ ìœ„ì—ì„œ ì •ì˜í•œ mock í•¨ìˆ˜ í˜¸ì¶œ
    if not api_key:
        return mock_response_data(keywords), "ğŸŸ¡ Simulation", 0

    try:
        client = OpenAI(api_key=api_key)

        # ì˜ì–´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë¹„ìš© ì ˆê°)
        system_prompt = """
        You are a professional PD and copywriter for a YouTube channel with 1 million subscribers.
        Your goal is to create attractive titles that maximize Click-Through Rate (CTR).

        You must adhere to the following principles:
        1. Trend Integration: Naturally incorporate the provided [Trending Keywords] into the title.
        2. Hook Elements: Use psychological techniques such as stimulating curiosity, posing problems, or specific numbers.
        3. Conciseness: Prefer titles within 30 characters (Max 50).
        4. No Clickbait/Lies: Absolutely no misleading titles unrelated to the video content.

        Output must be in JSON format only.
        """

        user_prompt = f"""
        Analyze the following video info and suggest 3 titles.

        [Video Info]
        - Category: {category}
        - Summary: {video_summary}
        - Target Audience: {target_audience}
        - Trending Keywords to use: {keywords_str}

        [Output Format]
        Return a JSON object with a 'suggestions' list.
        Each item must have 'title' (in Korean), 'strategy', and 'keywords_used'.
        """

        # GPT í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            response_format={"type": "json_object"},
            temperature=0.75
        )

        result_text = response.choices[0].message.content
        result_json = json.loads(result_text)

        # ë¹„ìš© ê³„ì‚°
        usage = response.usage
        cost = (usage.prompt_tokens * 0.15 + usage.completion_tokens * 0.60) / 1_000_000

        return result_json, "ğŸŸ¢ Real AI (GPT-4o-mini)", cost

    except Exception as e:
        return {"error": str(e)}, "ğŸ”´ Error", 0

# ==========================================
# 4. ì‹¤í–‰ë¶€
# ==========================================

# âš ï¸ OpenAI API í‚¤ ì…ë ¥
OPENAI_API_KEY = ""

# ì…ë ¥ ë°ì´í„°
CATEGORY = "ì—¬í–‰"
SUMMARY = "ì˜¤ì‚¬ì¹´ ìœ ë‹ˆë²„ì…œ ìŠ¤íŠœë””ì˜¤ ì¬íŒ¬, ë‹Œí…ë„ ì›”ë“œ ì…ì¥ê¶Œ ì‹¸ê²Œ ì‚¬ëŠ” ë²•ê³¼ ì˜¤í”ˆëŸ° ê¿€íŒ ì •ë¦¬"
TARGET = "ì¼ë³¸ ì—¬í–‰ì„ ê³„íš ì¤‘ì¸ 2030 ì»¤í”Œ"

print(f"ğŸš€ Hookly PD ì—”ì§„ ê°€ë™... (Category: {CATEGORY})\n")
result, mode, cost = generate_titles_final(OPENAI_API_KEY, CATEGORY, SUMMARY, TARGET)

# ê²°ê³¼ ì¶œë ¥
print(f"Mode: {mode}")
if mode.startswith("ğŸŸ¢"):
    print(f"ğŸ’¸ ë¹„ìš©: ${cost:.6f} (ì•½ {cost * 1350:.2f}ì›)")

if "suggestions" in result:
    df = pd.DataFrame(result['suggestions'])
    display(df)
else:
    print(result)
